{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcJK3kXl--c3"
   },
   "source": [
    "# Assignment 1-1: PyTorch 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 있는 코드 셀은 jupyter notebook에서 import한 python 모듈을 수정한 경우 자동으로 반영되도록 합니다.<br>\n",
    "만약 아래 코드를 실행하지 않는 경우 python 코드를 변경하면 jupyter notebook kernel을 restart해야합니다.<br>\n",
    "참고: 아래 코드 셀 실행 시 에러가 나는 경우 notebook kernel을 재시작하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5PzjwH7VTO4"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qc83ETI1a3o9"
   },
   "source": [
    "# Introduction\n",
    "이 notebook에서는 과제에서 사용할 PyTorch의 핵심 기능들을 다룹니다.\n",
    "참고로 몇몇 notebook cell과 py 파일에는 아래와 같이 코드 블록이 있습니다.\n",
    "\n",
    "```python\n",
    "##########################################################################\n",
    "#                     TODO: 여기에 코드를 작성하세요                           #\n",
    "##########################################################################\n",
    "pass\n",
    "##########################################################################\n",
    "#                            코드 끝                                       #\n",
    "##########################################################################\n",
    "```\n",
    "\n",
    "여기서 pass 문을 직접 작성한 코드로 교체하고 나머지 블록은 그대로 두어야 합니다 (아래 예시와 같이 TODO 코드 블록 사이를 제외하고는 절대 다른 코드를 수정하면 안됩니다).\n",
    "\n",
    "```python\n",
    "##########################################################################\n",
    "#                     TODO: 여기에 코드를 작성하세요                           #\n",
    "##########################################################################\n",
    "y = m * x + b\n",
    "##########################################################################\n",
    "#                            코드 끝                                       #\n",
    "##########################################################################\n",
    "```\n",
    "\n",
    "Notebook을 작성할 때는 다음 규칙을 반드시 지켜야 합니다:\n",
    "- 코드 블록 바깥의 코드를 수정하거나 작성하지 말 것\n",
    "- 노트북의 셀을 추가하거나 삭제하지 말 것. 단, 연습용으로 새 셀을 추가할 수는 있으나 제출 전 삭제해야 함\n",
    "- **제출 전에 모든 셀을 실행할 것. 실행된 코드만 점수로 인정됩니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1MEmHrgBsgX4"
   },
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3e_Nux0siHo"
   },
   "source": [
    "PyTorch는 오픈 소스 머신러닝 프레임워크입니다.\n",
    "PyTorch는 몇 가지 주요 기능을 제공합니다.\n",
    "- 다차원 Tensor 객체: numpy와 유사하지만 GPU 가속 지원\n",
    "- 최적화된 autograd 엔진: 자동으로 미분 계산 수행\n",
    "- 모듈화된 API: 딥러닝 모델 구축 및 배포 지원\n",
    "\n",
    "본 과제에서는 PyTorch 2.0 버전 이상이면 큰 무리 없이 동작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sydFm14itrqq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HrBSx6hYu8ca"
   },
   "source": [
    "## Tensor 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWagwmXuvIle"
   },
   "source": [
    "### Creating and Accessing tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bf_SY4RzvAh_"
   },
   "source": [
    "torch `tensor`는 같은 타입의 값들로 이루어진 다차원 배열입니다. index는 0 이상의 정수 tuple을 사용합니다.\n",
    "차원의 개수는 rank, 각 차원의 크기를 담은 튜플은 shape라고 합니다.\n",
    "<br>\n",
    "torch `tensor`는 중첩된 Python 리스트로 만들 수 있고 대괄호를 이용해 element를 조회하거나 수정할 수 있습니다.\n",
    "\n",
    "element를 꺼내면 PyTorch의 scalar 타입이 나오는데 필요하다면 .item() 메서드로 Python scalar로 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5039,
     "status": "aborted",
     "timestamp": 1599236804358,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "IpwfVUvPu_lF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a:\n",
      "tensor([1, 2, 3])\n",
      "type(a):  <class 'torch.Tensor'>\n",
      "rank of a:  1\n",
      "a.shape:  torch.Size([3])\n",
      "\n",
      "a[0]:  tensor(1)\n",
      "type(a[0]):  <class 'torch.Tensor'>\n",
      "type(a[0].item()):  <class 'int'>\n",
      "\n",
      "a after mutating:\n",
      "tensor([ 1, 10,  3])\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 tensor from a Python list\n",
    "a = torch.tensor([1, 2, 3])\n",
    "print('Here is a:')\n",
    "print(a)\n",
    "print('type(a): ', type(a))\n",
    "print('rank of a: ', a.dim())\n",
    "print('a.shape: ', a.shape)\n",
    "\n",
    "# Access elements using square brackets\n",
    "print()\n",
    "print('a[0]: ', a[0])\n",
    "print('type(a[0]): ', type(a[0]))\n",
    "print('type(a[0].item()): ', type(a[0].item()))\n",
    "\n",
    "# Mutate elements using square brackets\n",
    "a[1] = 10\n",
    "print()\n",
    "print('a after mutating:')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZq4zsnLEgXH"
   },
   "source": [
    "위 예시는 1차원 tensor를 보여줍니다. 같은 방식으로 2차원 이상 tensor도 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5034,
     "status": "aborted",
     "timestamp": 1599236804359,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "7TcvHxpTFUcL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is b:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 5]])\n",
      "rank of b: 2\n",
      "b.shape:  torch.Size([2, 3])\n",
      "\n",
      "b[0, 1]: tensor(2)\n",
      "b[1, 2]: tensor(5)\n",
      "\n",
      "b after mutating:\n",
      "tensor([[  1,   2,   3],\n",
      "        [  4, 100,   5]])\n"
     ]
    }
   ],
   "source": [
    "# Create a two-dimensional tensor\n",
    "b = torch.tensor([[1, 2, 3], [4, 5, 5]])\n",
    "print('Here is b:')\n",
    "print(b)\n",
    "print('rank of b:', b.dim())\n",
    "print('b.shape: ', b.shape)\n",
    "\n",
    "# Access elements from a multidimensional tensor\n",
    "print()\n",
    "print('b[0, 1]:', b[0, 1])\n",
    "print('b[1, 2]:', b[1, 2])\n",
    "\n",
    "# Mutate elements of a multidimensional tensor\n",
    "b[1, 1] = 100\n",
    "print()\n",
    "print('b after mutating:')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BBOsvh53GXa8"
   },
   "source": [
    "#### 직접 구현하기\n",
    "\n",
    "이제는 직접 과제를 해볼 차례입니다.<br>\n",
    "파일명 `pytorch101.py` 안에 있는 함수들 `create_sample_tensor`, `mutate_tensor`, `count_tensor_elements` 를 완성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5029,
     "status": "aborted",
     "timestamp": 1599236804360,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "zjCIUzbaVTPs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the sample tensor:\n",
      "tensor([[  0,  10],\n",
      "        [100,   0],\n",
      "        [  0,   0]])\n",
      "\n",
      "After mutating:\n",
      "tensor([[ 4, 10],\n",
      "        [ 5,  6],\n",
      "        [ 0,  0]])\n",
      "\n",
      "Correct shape:  True\n",
      "x[0, 0] correct:  True\n",
      "x[1, 0] correct:  True\n",
      "x[1, 1] correct:  True\n",
      "\n",
      "Number of elements in x:  6\n",
      "Correctly counted:  True\n"
     ]
    }
   ],
   "source": [
    "from pytorch101 import create_sample_tensor, mutate_tensor, count_tensor_elements\n",
    "\n",
    "# Create a sample tensor\n",
    "x = create_sample_tensor()\n",
    "print('Here is the sample tensor:')\n",
    "print(x)\n",
    "\n",
    "# Mutate the tensor by setting a few elements\n",
    "indices = [(0, 0), (1, 0), (1, 1)]\n",
    "values = [4, 5, 6]\n",
    "mutate_tensor(x, indices, values)\n",
    "print('\\nAfter mutating:')\n",
    "print(x)\n",
    "print('\\nCorrect shape: ', x.shape == (3, 2))\n",
    "print('x[0, 0] correct: ', x[0, 0].item() == 4)\n",
    "print('x[1, 0] correct: ', x[1, 0].item() == 5)\n",
    "print('x[1, 1] correct: ', x[1, 1].item() == 6)\n",
    "\n",
    "# Check the number of elements in the sample tensor\n",
    "num = count_tensor_elements(x)\n",
    "print('\\nNumber of elements in x: ', num)\n",
    "print('Correctly counted: ', num == 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yz_VDA3IvP33"
   },
   "source": [
    "### Tensor 생성자(constructors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BoAlslEdwV-k"
   },
   "source": [
    "PyTorch에는 `tensor`를 만들기 위한 편리한 메서드들이 많이 있습니다. 이를 사용하면 비효율적인 Python 리스트를 굳이 사용할 필요가 없습니다.<br>\n",
    "자주 사용하는 생성 함수 몇 가지는 다음과 같습니다.\n",
    "\n",
    "- [`torch.zeros`](https://pytorch.org/docs/stable/generated/torch.zeros.html): Creates a tensor of all zeros\n",
    "- [`torch.ones`](https://pytorch.org/docs/stable/generated/torch.ones.html): Creates a tensor of all ones\n",
    "- [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html): Creates a tensor with uniform random numbers\n",
    "\n",
    "`tensor` 생성 관련 함수 전체 목록은 [여기서](https://pytorch.org/docs/stable/torch.html#creation-ops) 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5023,
     "status": "aborted",
     "timestamp": 1599236804360,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "FL6DXGXzxHBA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor of zeros:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "tensor of ones:\n",
      "tensor([[1., 1.]])\n",
      "\n",
      "identity matrix:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "\n",
      "random tensor:\n",
      "tensor([[0.4825, 0.0429, 0.0406, 0.3353, 0.6505],\n",
      "        [0.8192, 0.2309, 0.7211, 0.8255, 0.4244],\n",
      "        [0.2049, 0.0709, 0.6181, 0.1936, 0.9888],\n",
      "        [0.2185, 0.9946, 0.5448, 0.8383, 0.6120]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "a = torch.zeros(2, 3)\n",
    "print('tensor of zeros:')\n",
    "print(a)\n",
    "\n",
    "# Create a tensor of all ones\n",
    "b = torch.ones(1, 2)\n",
    "print('\\ntensor of ones:')\n",
    "print(b)\n",
    "\n",
    "# Create a 3x3 identity matrix\n",
    "c = torch.eye(3)\n",
    "print('\\nidentity matrix:')\n",
    "print(c)\n",
    "\n",
    "# Tensor of random values\n",
    "d = torch.rand(4, 5)\n",
    "print('\\nrandom tensor:')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9QuvWYxMsoK"
   },
   "source": [
    "#### 직접 구현하기\n",
    "\n",
    "`pytorch101.py` 파일에 있는 `create_tensor_of_pi` 함수를 완성하세요.\n",
    "Hint: [`torch.full`](https://pytorch.org/docs/stable/generated/torch.full.html#torch.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5019,
     "status": "aborted",
     "timestamp": 1599236804361,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "N_y7Z5I0NIaA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is a tensor: True\n",
      "x has correct shape:  True\n",
      "x is filled with pi:  True\n"
     ]
    }
   ],
   "source": [
    "from pytorch101 import create_tensor_of_pi\n",
    "\n",
    "x = create_tensor_of_pi(4, 5)\n",
    "\n",
    "print('x is a tensor:', torch.is_tensor(x))\n",
    "print('x has correct shape: ', x.shape == (4, 5))\n",
    "print('x is filled with pi: ', (x == 3.14).all().item() == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rz_hiJD33fu1"
   },
   "source": [
    "### Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5015,
     "status": "aborted",
     "timestamp": 1599236804361,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "vREVDf_n31Qz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype when torch chooses for us:\n",
      "List of integers: torch.int64\n",
      "List of floats: torch.float32\n",
      "Mixed list: torch.float32\n",
      "\n",
      "dtype when we force a datatype:\n",
      "32-bit float:  torch.float32\n",
      "32-bit integer:  torch.int32\n",
      "64-bit integer:  torch.int64\n",
      "\n",
      "torch.ones with different dtypes\n",
      "default dtype: torch.float32\n",
      "16-bit integer: torch.int16\n",
      "8-bit unsigned integer: torch.uint8\n"
     ]
    }
   ],
   "source": [
    "# Let torch choose the datatype\n",
    "x0 = torch.tensor([1, 2])   # List of integers\n",
    "x1 = torch.tensor([1., 2.]) # List of floats\n",
    "x2 = torch.tensor([1., 2])  # Mixed list\n",
    "print('dtype when torch chooses for us:')\n",
    "print('List of integers:', x0.dtype)\n",
    "print('List of floats:', x1.dtype)\n",
    "print('Mixed list:', x2.dtype)\n",
    "\n",
    "# Force a particular datatype\n",
    "y0 = torch.tensor([1, 2], dtype=torch.float32)  # 32-bit float\n",
    "y1 = torch.tensor([1, 2], dtype=torch.int32)    # 32-bit (signed) integer\n",
    "y2 = torch.tensor([1, 2], dtype=torch.int64)    # 64-bit (signed) integer\n",
    "print('\\ndtype when we force a datatype:')\n",
    "print('32-bit float: ', y0.dtype)\n",
    "print('32-bit integer: ', y1.dtype)\n",
    "print('64-bit integer: ', y2.dtype)\n",
    "\n",
    "# Other creation ops also take a dtype argument\n",
    "z0 = torch.ones(1, 2)  # Let torch choose for us\n",
    "z1 = torch.ones(1, 2, dtype=torch.int16) # 16-bit (signed) integer\n",
    "z2 = torch.ones(1, 2, dtype=torch.uint8) # 8-bit (unsigned) integer\n",
    "print('\\ntorch.ones with different dtypes')\n",
    "print('default dtype:', z0.dtype)\n",
    "print('16-bit integer:', z1.dtype)\n",
    "print('8-bit unsigned integer:', z2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GG1xBunZ3ixx"
   },
   "source": [
    "위 예시에서 어떤 tensor는 실수(float) 값을, 또 어떤 tensor는 정수(int) 값을 가지고 있다는 걸 확인할 수 있습니다.\n",
    "\n",
    "PyTorch는 tensor를 만들 때 사용할 수 있는 다양한 숫자 데이터 타입을 제공합니다.\n",
    "tensor를 생성할 때 PyTorch는 보통 자동으로 적절한 데이터 타입을 추측합니다.\n",
    "하지만 tensor 생성 함수에는 보통 `dtype` 인자가 있어서 원하는 데이터 타입을 직접 지정할 수도 있습니다.\n",
    "\n",
    "모든 tensor에는 `dtype` 속성이 있어서 현재 데이터 타입을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W2reBgQmx_x4"
   },
   "source": [
    "tensor는 다른 데이터 타입으로 변환(cast) 할 수 있습니다.\n",
    "이를 위해 [.to()](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) 메서드를 사용할 수 있습니다.<br>\n",
    "또한 자주 쓰이는 변환을 위해 [.float()](https://pytorch.org/docs/stable/generated/torch.Tensor.float.html), [.long()](https://pytorch.org/docs/stable/generated/torch.Tensor.long.html) 같은 메서드도 제공됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5008,
     "status": "aborted",
     "timestamp": 1599236804362,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "sAMpwGsdyHAw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: torch.int64\n",
      "x1: torch.float32\n",
      "x2: torch.float64\n",
      "x3: torch.float32\n",
      "x4: torch.float64\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.eye(3, dtype=torch.int64)\n",
    "x1 = x0.float()  # Cast to 32-bit float\n",
    "x2 = x0.double() # Cast to 64-bit float\n",
    "x3 = x0.to(torch.float32) # Alternate way to cast to 32-bit float\n",
    "x4 = x0.to(torch.float64) # Alternate way to cast to 64-bit float\n",
    "print('x0:', x0.dtype)\n",
    "print('x1:', x1.dtype)\n",
    "print('x2:', x2.dtype)\n",
    "print('x3:', x3.dtype)\n",
    "print('x4:', x4.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2O8Atl1wMB7"
   },
   "source": [
    "PyTorch는 다른 tensor와 동일한 데이터 타입을 가진 새로운 tensor를 만드는 여러 방법을 제공합니다:\n",
    "- [torch.zeros_like()](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) 같은 생성 함수는 주어진 tensor와 동일한 shape과 dtype을 가진 새 tensor를 만듭니다.\n",
    "- tensor 객체에는 [.new_zeros()](https://pytorch.org/docs/stable/generated/torch.Tensor.new_zeros.html) 같은 인스턴스 메서드가 있어서, dtype은 같지만 shape은 다를 수 있는 tensor를 생성할 수 있습니다.\n",
    "- tensor의 인스턴스 메서드 [.to()](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html)는 다른 tensor를 인자로 받을 수 있으며, 이 경우 그 tensor의 dtype으로 변환(cast)됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5003,
     "status": "aborted",
     "timestamp": 1599236804363,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "1APDsx54xV6p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 shape is torch.Size([3, 3]), dtype is torch.float64\n",
      "x1 shape is torch.Size([3, 3]), dtype is torch.float64\n",
      "x2 shape is torch.Size([4, 5]), dtype is torch.float64\n",
      "x3 shape is torch.Size([6, 7]), dtype is torch.float64\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.eye(3, dtype=torch.float64)  # Shape (3, 3), dtype torch.float64\n",
    "x1 = torch.zeros_like(x0)               # Shape (3, 3), dtype torch.float64\n",
    "x2 = x0.new_zeros(4, 5)                 # Shape (4, 5), dtype torch.float64\n",
    "x3 = torch.ones(6, 7).to(x0)            # Shape (6, 7), dtype torch.float64)\n",
    "print('x0 shape is %r, dtype is %r' % (x0.shape, x0.dtype))\n",
    "print('x1 shape is %r, dtype is %r' % (x1.shape, x1.dtype))\n",
    "print('x2 shape is %r, dtype is %r' % (x2.shape, x2.dtype))\n",
    "print('x3 shape is %r, dtype is %r' % (x3.shape, x3.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPuGPa0v4h_2"
   },
   "source": [
    "#### 직접 구현하기\n",
    "\n",
    "`pytorch101.py` 파일의 `multiples_of_ten` 함수를 구현하세요.\n",
    "이 함수는 주어진 범위 안의 10의 배수를 모두 담은 tensor를 만들고, dtype은 `torch.float64`로 설정해야 합니다. Hint: [torch.arange](https://pytorch.org/docs/stable/generated/torch.arange.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4998,
     "status": "aborted",
     "timestamp": 1599236804363,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "Qddo6C5Bgwcr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct dtype:  True\n",
      "Correct shape:  True\n",
      "Correct values:  True\n",
      "\n",
      "Correct dtype:  True\n",
      "Correct shape:  True\n"
     ]
    }
   ],
   "source": [
    "from pytorch101 import multiples_of_ten\n",
    "\n",
    "start = 5\n",
    "stop = 25\n",
    "x = multiples_of_ten(start, stop)\n",
    "print('Correct dtype: ', x.dtype == torch.float64)\n",
    "print('Correct shape: ', x.shape == (2,))\n",
    "print('Correct values: ', x.tolist() == [10, 20])\n",
    "\n",
    "# If there are no multiples of ten in the given range you should return an empty tensor\n",
    "start = 5\n",
    "stop = 7\n",
    "x = multiples_of_ten(start, stop)\n",
    "print('\\nCorrect dtype: ', x.dtype == torch.float64)\n",
    "print('Correct shape: ', x.shape == (0,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwJL3HVySvXn"
   },
   "source": [
    "PyTorch에는 다양한 숫자 데이터 타입이 있지만 가장 자주 쓰이는 타입은 다음과 같습니다.\n",
    "- `torch.float32`: 기본 실수형으로, 학습 가능한 파라미터나 네트워크 활성값 등을 저장하는 데 사용됩니다. 거의 모든 연산이 이 타입으로 수행됩니다.\n",
    "- `torch.int64`: 보통 인덱스를 저장할 때 사용됩니다.\n",
    "- `torch.bool`: 불리언 값을 저장합니다.\n",
    "- `torch.float16`: 혼합 정밀도 연산(mixed-precision arithmetic)에 사용되며, 보통 NVIDIA GPU의 tensor cores(https://www.nvidia.com/en-us/data-center/tensorcore/) 에서 활용됩니다. 이 강의에서는 따로 다루지는 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlANfnILvX3S"
   },
   "source": [
    "## Tensor indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KP4dRrHhyLO5"
   },
   "source": [
    "앞에서 우리는 PyTorch tensor의 개별 element를 가져오거나 수정하는 방법을 보았습니다.\n",
    "PyTorch는 이 외에도 다양한 방식으로 tensor에 인덱싱할 수 있는 기능을 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mo-PoTWNvbba"
   },
   "source": [
    "### Slice indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qUqTYvglyVLc"
   },
   "source": [
    "Python 리스트나 numpy 배열과 마찬가지로 PyTorch tensor도 start:stop 또는 start:stop:step 문법으로 슬라이싱(slicing) 할 수 있습니다.\n",
    "여기서 stop 인덱스는 항상 포함되지 않습니다.<br>\n",
    "즉, 슬라이스에서 제외되는 첫 번째 원소를 가리킵니다.\n",
    "\n",
    "start와 stop 인덱스는 음수도 될 수 있으며, 이 경우 tensor의 끝에서부터 거꾸로 센 값을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4993,
     "status": "aborted",
     "timestamp": 1599236804364,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "yEr5BzdUdCtZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([ 0, 11, 22, 33, 44, 55, 66])\n",
      "1 tensor([22, 33, 44])\n",
      "2 tensor([22, 33, 44, 55, 66])\n",
      "3 tensor([ 0, 11, 22, 33, 44])\n",
      "4 tensor([ 0, 11, 22, 33, 44, 55, 66])\n",
      "5 tensor([11, 33])\n",
      "6 tensor([ 0, 11, 22, 33, 44, 55])\n",
      "7 tensor([33, 55])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0, 11, 22, 33, 44, 55, 66])\n",
    "print(0, a)        # (0) Original tensor\n",
    "print(1, a[2:5])   # (1) Elements between index 2 and 5\n",
    "print(2, a[2:])    # (2) Elements after index 2\n",
    "print(3, a[:5])    # (3) Elements before index 5\n",
    "print(4, a[:])     # (4) All elements\n",
    "print(5, a[1:5:2]) # (5) Every second element between indices 1 and 5\n",
    "print(6, a[:-1])   # (6) All but the last element\n",
    "print(7, a[-4::2]) # (7) Every second element, starting from the fourth-last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yrcr9PojgTS1"
   },
   "source": [
    "다차원 tensor의 경우, 각 차원마다 슬라이스나 정수를 지정해서 원하는 형태의 서브텐서(subtensor)를 뽑아낼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4987,
     "status": "aborted",
     "timestamp": 1599236804364,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "S5fOdjTUyhNf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "shape:  torch.Size([3, 4])\n",
      "\n",
      "Single row:\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([5, 6, 7, 8])\n",
      "shape:  torch.Size([4])\n",
      "\n",
      "Single column:\n",
      "tensor([ 2,  6, 10])\n",
      "shape:  torch.Size([3])\n",
      "\n",
      "First two rows, last two columns:\n",
      "tensor([[2, 3, 4],\n",
      "        [6, 7, 8]])\n",
      "shape:  torch.Size([2, 3])\n",
      "\n",
      "Every other row, middle columns:\n",
      "tensor([[ 2,  3],\n",
      "        [10, 11]])\n",
      "shape:  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Create the following rank 2 tensor with shape (3, 4)\n",
    "# [[ 1  2  3  4]\n",
    "#  [ 5  6  7  8]\n",
    "#  [ 9 10 11 12]]\n",
    "a = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "print('Original tensor:')\n",
    "print(a)\n",
    "print('shape: ', a.shape)\n",
    "\n",
    "# Get row 1, and all columns. \n",
    "print('\\nSingle row:')\n",
    "print(a[1, :])\n",
    "print(a[1])  # Gives the same result; we can omit : for trailing dimensions\n",
    "print('shape: ', a[1].shape)\n",
    "\n",
    "print('\\nSingle column:')\n",
    "print(a[:, 1])\n",
    "print('shape: ', a[:, 1].shape)\n",
    "\n",
    "# Get the first two rows and the last three columns\n",
    "print('\\nFirst two rows, last two columns:')\n",
    "print(a[:2, -3:])\n",
    "print('shape: ', a[:2, -3:].shape)\n",
    "\n",
    "# Get every other row, and columns at index 1 and 2\n",
    "print('\\nEvery other row, middle columns:')\n",
    "print(a[::2, 1:3])\n",
    "print('shape: ', a[::2, 1:3].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gOsR8Pdertku"
   },
   "source": [
    "tensor에서 한 행(column)이나 한 열(row)을 꺼내는 데에는 두 가지 방법이 있습니다.\n",
    "정수를 사용하면 rank가 1만큼 줄어들고, 길이가 1인 슬라이스를 사용하면 rank가 유지됩니다.<br>\n",
    "주의: 이 동작은 MATLAB과는 다르게 동작합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4983,
     "status": "aborted",
     "timestamp": 1599236804365,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "P1kHcc5jsF-c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "\n",
      "Two ways of accessing a single row:\n",
      "tensor([5, 6, 7, 8]) torch.Size([4])\n",
      "tensor([[5, 6, 7, 8]]) torch.Size([1, 4])\n",
      "\n",
      "Two ways of accessing a single column:\n",
      "tensor([ 2,  6, 10]) torch.Size([3])\n",
      "tensor([[ 2],\n",
      "        [ 6],\n",
      "        [10]]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Create the following rank 2 tensor with shape (3, 4)\n",
    "a = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "print('Original tensor')\n",
    "print(a)\n",
    "\n",
    "row_r1 = a[1, :]    # Rank 1 view of the second row of a  \n",
    "row_r2 = a[1:2, :]  # Rank 2 view of the second row of a\n",
    "print('\\nTwo ways of accessing a single row:')\n",
    "print(row_r1, row_r1.shape)\n",
    "print(row_r2, row_r2.shape)\n",
    "\n",
    "# We can make the same distinction when accessing columns:\n",
    "col_r1 = a[:, 1]\n",
    "col_r2 = a[:, 1:2]\n",
    "print('\\nTwo ways of accessing a single column:')\n",
    "print(col_r1, col_r1.shape)\n",
    "print(col_r2, col_r2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jk625fJfyxV8"
   },
   "source": [
    "tensor를 슬라이싱하면 원본 데이터를 공유하는 **view**가 반환됩니다. 따라서 슬라이스를 수정하면 원본 tensor도 함께 바뀝니다.\n",
    "<br>\n",
    "이걸 피하려면 `clone()` 메서드를 사용해 tensor의 복사본을 만들면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4978,
     "status": "aborted",
     "timestamp": 1599236804365,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "IXbikYPwyxGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before mutating:\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "tensor([2, 3, 4])\n",
      "tensor([2, 3, 4])\n",
      "\n",
      "After mutating:\n",
      "tensor([[ 1, 20, 30,  4],\n",
      "        [ 5,  6,  7,  8]])\n",
      "tensor([20, 30,  4])\n",
      "tensor([ 2,  3, 40])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor, a slice, and a clone of a slice\n",
    "a = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "b = a[0, 1:]\n",
    "c = a[0, 1:].clone()\n",
    "print('Before mutating:')\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "a[0, 1] = 20  # a[0, 1] and b[0] point to the same element\n",
    "b[1] = 30     # b[1] and a[0, 2] point to the same element\n",
    "c[2] = 40     # c is a clone, so it has its own data\n",
    "print('\\nAfter mutating:')\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "print(a.untyped_storage().data_ptr() == c.untyped_storage().data_ptr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5t5omyKwm9dB"
   },
   "source": [
    "#### 직접 구현하기\n",
    "`slice_indexing_practice` 함수를 구현하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4976,
     "status": "aborted",
     "timestamp": 1599236804366,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "yKq2mswvqMmw"
   },
   "outputs": [],
   "source": [
    "# We will use this helper function to check your results\n",
    "def check(orig, actual, expected):\n",
    "    if not torch.is_tensor(actual):\n",
    "        return False\n",
    "    expected = torch.tensor(expected)\n",
    "    same_elements = (actual == expected).all().item()\n",
    "    same_storage = (orig.storage().data_ptr() == actual.storage().data_ptr())\n",
    "    return same_elements and same_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4971,
     "status": "aborted",
     "timestamp": 1599236804366,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "5-5UtVXPVTQL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_row:\n",
      "tensor([11, 12, 13, 14, 15])\n",
      "Correct: True\n",
      "\n",
      "third_col:\n",
      "tensor([[ 3],\n",
      "        [ 8],\n",
      "        [13]])\n",
      "Correct: True\n",
      "\n",
      "first_two_rows_three_cols:\n",
      "tensor([[1, 2, 3],\n",
      "        [6, 7, 8]])\n",
      "Correct: True\n",
      "\n",
      "even_rows_odd_cols:\n",
      "tensor([[ 2,  4],\n",
      "        [12, 14]])\n",
      "Correct: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pytorch101 import slice_indexing_practice\n",
    "\n",
    "# Create the following rank 2 tensor of shape (3, 5)\n",
    "# [[ 1  2  3  4  5]\n",
    "#  [ 6  7  8  9 10]\n",
    "#  [11 12 13 14 15]]\n",
    "x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 8, 10], [11, 12, 13, 14, 15]])\n",
    "out = slice_indexing_practice(x)\n",
    "\n",
    "last_row = out[0]\n",
    "print('last_row:')\n",
    "print(last_row)\n",
    "correct = check(x, last_row, [11, 12, 13, 14, 15])\n",
    "print('Correct: %r\\n' % correct)\n",
    "\n",
    "third_col = out[1]\n",
    "print('third_col:')\n",
    "print(third_col)\n",
    "correct = check(x, third_col, [[3], [8], [13]])\n",
    "print('Correct: %r\\n' % correct)\n",
    "\n",
    "first_two_rows_three_cols = out[2]\n",
    "print('first_two_rows_three_cols:')\n",
    "print(first_two_rows_three_cols)\n",
    "correct = check(x, first_two_rows_three_cols, [[1, 2, 3], [6, 7, 8]])\n",
    "print('Correct: %r\\n' % correct)\n",
    "\n",
    "even_rows_odd_cols = out[3]\n",
    "print('even_rows_odd_cols:')\n",
    "print(even_rows_odd_cols)\n",
    "correct = check(x, even_rows_odd_cols, [[2, 4], [12, 14]])\n",
    "print('Correct: %r\\n' % correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RNjhLwb0xY2A"
   },
   "source": [
    "지금까지는 슬라이싱을 이용해 서브텐서를 액세스(access) 하는 방법에 대해 다루었습니다.\n",
    "\n",
    "하지만 슬라이싱은 수정(modify) 용도로도 사용할 수 있습니다.<br>\n",
    "이때는 왼쪽에 슬라이스 표현식을 두고 오른쪽에는 상수 혹은 같은 shape를 가지는 tensor를 할당하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4967,
     "status": "aborted",
     "timestamp": 1599236804367,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "DFnky42Rx2I5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 2, 3],\n",
      "        [1, 1, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2, 4, dtype=torch.int64)\n",
    "a[:, :2] = 1\n",
    "a[:, 2:] = torch.tensor([[2, 3], [4, 5]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPVCQ5HszihV"
   },
   "source": [
    "#### 직접 구현하기\n",
    "`slice_assignment_practice` 함수를 구현하세요.<br>\n",
    "이 함수는 슬라이스 할당(slicing assignment)을 사용해 입력 tensor의 앞 4행, 앞 6열을 다음과 같이 바꾸는 연습 문제입니다.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 2 & 2 & 2 & 2 \\\\\n",
    "0 & 1 & 2 & 2 & 2 & 2 \\\\\n",
    "3 & 4 & 3 & 4 & 5 & 5 \\\\\n",
    "3 & 4 & 3 & 4 & 5 & 5 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "구현 시 반드시 다음 조건을 지켜야 합니다:\n",
    "- 입력 tensor `x`를 제자리(in-place) 에서 수정하고 그대로 반환해야 합니다.\n",
    "- 앞 4행, 앞 6열만 수정해야 하며 나머지 원소는 그대로 두어야 합니다.\n",
    "- tensor 수정은 반드시 슬라이스 할당 연산으로만 해야 하며, 슬라이스에 정수를 대입해야 합니다.\n",
    "- 원하는 결과를 만들 때 슬라이싱 연산은 최대 6번까지만 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4962,
     "status": "aborted",
     "timestamp": 1599236804367,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "FzXlnFqAVTQQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is x before calling slice_assignment_practice:\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0]])\n",
      "Here is x after calling slice assignment practice:\n",
      "tensor([[0, 1, 2, 2, 2, 2, 0],\n",
      "        [0, 1, 2, 2, 2, 2, 0],\n",
      "        [3, 4, 3, 4, 5, 5, 0],\n",
      "        [3, 4, 3, 4, 5, 5, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0]])\n",
      "Correct:  True\n"
     ]
    }
   ],
   "source": [
    "from pytorch101 import slice_assignment_practice\n",
    "\n",
    "# note: this \"x\" has one extra row, intentionally\n",
    "x = torch.zeros(5, 7, dtype=torch.int64)\n",
    "print('Here is x before calling slice_assignment_practice:')\n",
    "print(x)\n",
    "slice_assignment_practice(x)\n",
    "print('Here is x after calling slice assignment practice:')\n",
    "print(x)\n",
    "\n",
    "expected = [\n",
    "    [0, 1, 2, 2, 2, 2, 0],\n",
    "    [0, 1, 2, 2, 2, 2, 0],\n",
    "    [3, 4, 3, 4, 5, 5, 0],\n",
    "    [3, 4, 3, 4, 5, 5, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0],\n",
    "]\n",
    "print('Correct: ', x.tolist() == expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4y93rPhGveWw"
   },
   "source": [
    "### Integer tensor indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GlTyhjEN0AIE"
   },
   "source": [
    "torch tensor를 슬라이싱으로 인덱싱하면 나오는 tensor의 view는 항상 원본 tensor의 서브배열입니다.<br>\n",
    "이 방식은 유용하지만 제약이 생기는 경우가 생길수도 있습니다.\n",
    "\n",
    "이때 인덱스 배열(index arrays) 을 사용하면 더 유연하게 tensor를 다룰 수 있고,\n",
    "슬라이스보다 훨씬 다양한 방식으로 새로운 tensor를 만들 수 있게 됩니다.<br>\n",
    "예를 들어 인덱스 배열을 사용하여 tensor의 행이나 열 순서를 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4957,
     "status": "aborted",
     "timestamp": 1599236804368,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "IXePPNkjM_SD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "\n",
      "Reordered rows:\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 1,  2,  3,  4],\n",
      "        [ 9, 10, 11, 12],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 5,  6,  7,  8]])\n",
      "\n",
      "Reordered columns:\n",
      "tensor([[ 4,  3,  2,  1],\n",
      "        [ 8,  7,  6,  5],\n",
      "        [12, 11, 10,  9]])\n"
     ]
    }
   ],
   "source": [
    "# Create the following rank 2 tensor with shape (3, 4)\n",
    "# [[ 1  2  3  4]\n",
    "#  [ 5  6  7  8]\n",
    "#  [ 9 10 11 12]]\n",
    "a = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "print('Original tensor:')\n",
    "print(a)\n",
    "\n",
    "# Create a new tensor of shape (5, 4) by reordering rows from a:\n",
    "# - First two rows same as the first row of a\n",
    "# - Third row is the same as the last row of a\n",
    "# - Fourth and fifth rows are the same as the second row from a\n",
    "idx = [0, 0, 2, 1, 1]  # index arrays can be Python lists of integers\n",
    "print('\\nReordered rows:')\n",
    "print(a[idx])\n",
    "\n",
    "# Create a new tensor of shape (3, 4) by reversing the columns from a\n",
    "idx = torch.tensor([3, 2, 1, 0])  # Index arrays can be int64 torch tensors\n",
    "print('\\nReordered columns:')\n",
    "print(a[:, idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CpIBR1bCQji6"
   },
   "source": [
    "원소가 N개 있는 인덱스 배열 `idx0`, `idx1`가 주어졌을 때 `a[idx0, idx1]`는 다음과 동일합니다.\n",
    "```\n",
    "torch.tensor([\n",
    "  a[idx0[0], idx1[0]],\n",
    "  a[idx0[1], idx1[1]],\n",
    "  ...,\n",
    "  a[idx0[N - 1], idx1[N - 1]]\n",
    "])\n",
    "```\n",
    "\n",
    "비슷하게 2차원 이상의 tensor에도 그대로 확장됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4952,
     "status": "aborted",
     "timestamp": 1599236804368,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "ocIR8R5ZSEaP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "\n",
      "Get the diagonal:\n",
      "tensor([1, 5, 9])\n",
      "\n",
      "After setting the diagonal:\n",
      "tensor([[11,  2,  3],\n",
      "        [ 4, 22,  6],\n",
      "        [ 7,  8, 33]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print('Original tensor:')\n",
    "print(a)\n",
    "\n",
    "idx = [0, 1, 2]\n",
    "print('\\nGet the diagonal:')\n",
    "print(a[idx, idx])\n",
    "\n",
    "# Modify the diagonal\n",
    "a[idx, idx] = torch.tensor([11, 22, 33])\n",
    "print('\\nAfter setting the diagonal:')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-cr-EqA0vfO"
   },
   "source": [
    "아래와 같이 정수 배열 인덱싱을 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4948,
     "status": "aborted",
     "timestamp": 1599236804369,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "HWA8E8iI0x17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "\n",
      "Select one element from each row:\n",
      "tensor([ 2,  6,  8, 10])\n",
      "\n",
      "After modifying one element from each row:\n",
      "tensor([[ 1,  0,  3],\n",
      "        [ 4,  5,  0],\n",
      "        [ 7,  0,  9],\n",
      "        [ 0, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# Create a new tensor from which we will select elements\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "print('Original tensor:')\n",
    "print(a)\n",
    "\n",
    "# Take on element from each row of a:\n",
    "# from row 0, take element 1;\n",
    "# from row 1, take element 2;\n",
    "# from row 2, take element 1;\n",
    "# from row 3, take element 0\n",
    "idx0 = torch.arange(a.shape[0])  # Quick way to build [0, 1, 2, 3]\n",
    "idx1 = torch.tensor([1, 2, 1, 0])\n",
    "print('\\nSelect one element from each row:')\n",
    "print(a[idx0, idx1])\n",
    "\n",
    "# Now set each of those elements to zero\n",
    "a[idx0, idx1] = 0\n",
    "print('\\nAfter modifying one element from each row:')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5_-WUmSVEoR"
   },
   "source": [
    "#### 직접 구현하기\n",
    "`shuffle_cols`, `reverse_rows`, `take_one_elem_per_col` 함수를 구현하세요.<br>\n",
    "각 함수에서는 입력 tensor에 대한 단 하나의 인덱싱 연산으로 결과 tensor를 만들어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4942,
     "status": "aborted",
     "timestamp": 1599236804369,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "FX05_ov5VTQZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is x:\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "\n",
      "Here is shuffle_cols(x):\n",
      "tensor([[ 1,  1,  3,  2],\n",
      "        [ 4,  4,  6,  5],\n",
      "        [ 7,  7,  9,  8],\n",
      "        [10, 10, 12, 11]])\n",
      "Correct: True\n",
      "\n",
      "Here is reverse_rows(x):\n",
      "tensor([[10, 11, 12],\n",
      "        [ 7,  8,  9],\n",
      "        [ 4,  5,  6],\n",
      "        [ 1,  2,  3]])\n",
      "Correct: True\n",
      "\n",
      "Here is take_one_elem_per_col(x):\n",
      "tensor([ 4,  2, 12])\n",
      "Correct: True\n"
     ]
    }
   ],
   "source": [
    "from pytorch101 import shuffle_cols, reverse_rows, take_one_elem_per_col\n",
    "\n",
    "# Build a tensor of shape (4, 3):\n",
    "# [[ 1,  2,  3],\n",
    "#  [ 4,  5,  6],\n",
    "#  [ 7,  8,  9],\n",
    "#  [10, 11, 12]]\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "print('Here is x:')\n",
    "print(x)\n",
    "\n",
    "y1 = shuffle_cols(x)\n",
    "print('\\nHere is shuffle_cols(x):')\n",
    "print(y1)\n",
    "expected = [[1, 1, 3, 2], [4, 4, 6, 5], [7, 7, 9, 8], [10, 10, 12, 11]]\n",
    "y1_correct = torch.is_tensor(y1) and y1.tolist() == expected\n",
    "print('Correct: %r\\n' % y1_correct)\n",
    "\n",
    "y2 = reverse_rows(x)\n",
    "print('Here is reverse_rows(x):')\n",
    "print(y2)\n",
    "expected = [[10, 11, 12], [7, 8, 9], [4, 5, 6], [1, 2, 3]]\n",
    "y2_correct = torch.is_tensor(y2) and y2.tolist() == expected\n",
    "print('Correct: %r\\n' % y2_correct)\n",
    "\n",
    "y3 = take_one_elem_per_col(x)\n",
    "print('Here is take_one_elem_per_col(x):')\n",
    "print(y3)\n",
    "expected = [4, 2, 12]\n",
    "y3_correct = torch.is_tensor(y3) and y3.tolist() == expected\n",
    "print('Correct: %r' % y3_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ad-xqELwyqpN"
   },
   "source": [
    "## Reshaping operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ql9_eXuU4OG8"
   },
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfPb_2BY0HKw"
   },
   "source": [
    "PyTorch에는 tensor의 shape을 다루는 다양한 방법이 있습니다.\n",
    "가장 기본적인 예는 [.view()](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) 입니다.<br>\n",
    "이 메서드는 입력한 tensor와 element 개수는 같지만, shape는 다른 새로운 tensor를 반환합니다.\n",
    "\n",
    ".view()를 사용하면 행렬을 벡터로 평탄화(flatten)할 수도 있고, rank-1 벡터를 rank-2 형태의 행렬(행 벡터나 열 벡터)로 바꿀 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4923,
     "status": "aborted",
     "timestamp": 1599236804371,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "kw-M7C_61FZK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "shape: torch.Size([2, 4])\n",
      "\n",
      "Flattened tensor:\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "shape: torch.Size([8])\n",
      "\n",
      "Row vector:\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8]])\n",
      "shape: torch.Size([1, 8])\n",
      "\n",
      "Column vector:\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8]])\n",
      "shape: torch.Size([8, 1])\n",
      "\n",
      "Rank 3 tensor:\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "shape: torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "print('Original tensor:')\n",
    "print(x0)\n",
    "print('shape:', x0.shape)\n",
    "\n",
    "# Flatten x0 into a rank 1 vector of shape (8,)\n",
    "x1 = x0.view(8)\n",
    "print('\\nFlattened tensor:')\n",
    "print(x1)\n",
    "print('shape:', x1.shape)\n",
    "\n",
    "# Convert x1 to a rank 2 \"row vector\" of shape (1, 8)\n",
    "x2 = x1.view(1, 8)\n",
    "print('\\nRow vector:')\n",
    "print(x2)\n",
    "print('shape:', x2.shape)\n",
    "\n",
    "# Convert x1 to a rank 2 \"column vector\" of shape (8, 1)\n",
    "x3 = x1.view(8, 1)\n",
    "print('\\nColumn vector:')\n",
    "print(x3)\n",
    "print('shape:', x3.shape)\n",
    "\n",
    "# Convert x1 to a rank 3 tensor of shape (2, 2, 2):\n",
    "x4 = x1.view(2, 2, 2)\n",
    "print('\\nRank 3 tensor:')\n",
    "print(x4)\n",
    "print('shape:', x4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHsZ8BPF2PEq"
   },
   "source": [
    "편의를 위해 .view()를 호출할 때 인자로 -1을 넣을 수 있습니다.\n",
    "이 경우 해당 차원의 크기가 자동으로 계산되어, 출력 tensor의 전체 element 수가 입력 tensor와 같게 맞춰집니다.\n",
    "<br>\n",
    "이 기능을 사용하면 tensor의 기존 shape에 상관없이 손쉽게 reshape 연산을 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4919,
     "status": "aborted",
     "timestamp": 1599236804372,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "qNWu-R_J2qFY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "x0_flat:\n",
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "x0_row:\n",
      "tensor([[1, 2, 3, 4, 5, 6]])\n",
      "\n",
      "x1:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "x1_flat:\n",
      "tensor([1, 2, 3, 4])\n",
      "x1_row:\n",
      "tensor([[1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# We can reuse these functions for tensors of different shapes\n",
    "def flatten(x):\n",
    "    return x.view(-1)\n",
    "\n",
    "def make_row_vec(x):\n",
    "    return x.view(1, -1)\n",
    "\n",
    "x0 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "x0_flat = flatten(x0)\n",
    "x0_row = make_row_vec(x0)\n",
    "print('x0:')\n",
    "print(x0)\n",
    "print('x0_flat:')\n",
    "print(x0_flat)\n",
    "print('x0_row:')\n",
    "print(x0_row)\n",
    "\n",
    "x1 = torch.tensor([[1, 2], [3, 4]])\n",
    "x1_flat = flatten(x1)\n",
    "x1_row = make_row_vec(x1)\n",
    "print('\\nx1:')\n",
    "print(x1)\n",
    "print('x1_flat:')\n",
    "print(x1_flat)\n",
    "print('x1_row:')\n",
    "print(x1_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DK-ZB5aB2NPq"
   },
   "source": [
    "이름에서 알 수 있듯이 `.view()`가 반환하는 tensor는 입력 tensor와 같은 데이터를 공유합니다.\n",
    "따라서 하나를 수정하면 다른 쪽도 함께 변경됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4914,
     "status": "aborted",
     "timestamp": 1599236804372,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "ebT99rUo2McN"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "x_flat = x.view(-1)\n",
    "print('x before modifying:')\n",
    "print(x)\n",
    "print('x_flat before modifying:')\n",
    "print(x_flat)\n",
    "\n",
    "x[0, 0] = 10   # x[0, 0] and x_flat[0] point to the same data\n",
    "x_flat[1] = 20 # x_flat[1] and x[0, 1] point to the same data\n",
    "\n",
    "print('\\nx after modifying:')\n",
    "print(x)\n",
    "print('x_flat after modifying:')\n",
    "print(x_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z150qBob4Wkz"
   },
   "source": [
    "### Swapping axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCMDxbyBys78"
   },
   "source": [
    "자주 쓰이는 또 다른 reshape 연산은 행렬의 전치(transpose)입니다.<br>\n",
    "사실 `.view()` 단독으로는 행렬을 transpose할 수 없는데, 그 이유는 view()가 원소를 row-major 순서로 처리하기 때문입니다.<br>\n",
    "일반적으로 `.view()`는 tensor에 새 차원을 추가하거나, 인접한 차원을 합칠 때만 써야 합니다.\n",
    "\n",
    "그 외의 reshape 연산을 하려면 보통 tensor의 축(axis)을 바꿀 수 있는 함수를 사용해야 합니다.\n",
    "가장 간단한 예는 `.t()`로 이는 행렬 전치를 위해 특별히 제공되는 함수입니다.\n",
    "\n",
    "이 함수는 [torch 모듈의 함수](https://pytorch.org/docs/stable/generated/torch.t.html#torch.t)로도 쓸 수 있고, [tensor 인스턴스 메서드](https://pytorch.org/docs/stable/generated/torch.Tensor.t.html)로도 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4911,
     "status": "aborted",
     "timestamp": 1599236804373,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "o_B4NuX6zQm-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Transposing with view DOES NOT WORK!\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "Transposed matrix:\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print('Original matrix:')\n",
    "print(x)\n",
    "print('\\nTransposing with view DOES NOT WORK!')\n",
    "print(x.view(3, 2))\n",
    "print('\\nTransposed matrix:')\n",
    "print(torch.t(x))\n",
    "print(x.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RN93xo98zn0v"
   },
   "source": [
    "2차원보다 더 큰 차원을 가진 tensor의 경우, [torch.transpose](https://pytorch.org/docs/stable/generated/torch.transpose.html) (혹은 인스턴스 메서드 버전(https://pytorch.org/docs/stable/generated/torch.Tensor.transpose.html))을 사용해 원하는 두 차원을 서로 바꿀 수 있습니다.\n",
    "\n",
    "여러 축을 동시에 바꾸고 싶다면, [torch.permute](https://pytorch.org/docs/stable/generated/torch.permute.html) (혹은 인스턴스 메서드 버전(https://pytorch.org/docs/stable/generated/torch.Tensor.permute.html))을 사용해 차원들의 순서를 자유롭게 재배치할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4906,
     "status": "aborted",
     "timestamp": 1599236804374,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "XgN7YB8YzzkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15, 16],\n",
      "         [17, 18, 19, 20],\n",
      "         [21, 22, 23, 24]]])\n",
      "shape: torch.Size([2, 3, 4])\n",
      "\n",
      "Swap axes 1 and 2:\n",
      "tensor([[[ 1,  5,  9],\n",
      "         [ 2,  6, 10],\n",
      "         [ 3,  7, 11],\n",
      "         [ 4,  8, 12]],\n",
      "\n",
      "        [[13, 17, 21],\n",
      "         [14, 18, 22],\n",
      "         [15, 19, 23],\n",
      "         [16, 20, 24]]])\n",
      "torch.Size([2, 4, 3])\n",
      "\n",
      "Permute axes\n",
      "tensor([[[ 1, 13],\n",
      "         [ 2, 14],\n",
      "         [ 3, 15],\n",
      "         [ 4, 16]],\n",
      "\n",
      "        [[ 5, 17],\n",
      "         [ 6, 18],\n",
      "         [ 7, 19],\n",
      "         [ 8, 20]],\n",
      "\n",
      "        [[ 9, 21],\n",
      "         [10, 22],\n",
      "         [11, 23],\n",
      "         [12, 24]]])\n",
      "shape: torch.Size([3, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of shape (2, 3, 4)\n",
    "x0 = torch.tensor([\n",
    "     [[1,  2,  3,  4],\n",
    "      [5,  6,  7,  8],\n",
    "      [9, 10, 11, 12]],\n",
    "     [[13, 14, 15, 16],\n",
    "      [17, 18, 19, 20],\n",
    "      [21, 22, 23, 24]]])\n",
    "print('Original tensor:')\n",
    "print(x0)\n",
    "print('shape:', x0.shape)\n",
    "\n",
    "# Swap axes 1 and 2; shape is (2, 4, 3)\n",
    "x1 = x0.transpose(1, 2)\n",
    "print('\\nSwap axes 1 and 2:')\n",
    "print(x1)\n",
    "print(x1.shape)\n",
    "\n",
    "# Permute axes; the argument (1, 2, 0) means:\n",
    "# - Make the old dimension 1 appear at dimension 0;\n",
    "# - Make the old dimension 2 appear at dimension 1;\n",
    "# - Make the old dimension 0 appear at dimension 2\n",
    "# This results in a tensor of shape (3, 4, 2)\n",
    "x2 = x0.permute(1, 2, 0)\n",
    "print('\\nPermute axes')\n",
    "print(x2)\n",
    "print('shape:', x2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4SJCVbf-bZ0"
   },
   "source": [
    "### Contiguous(연속된) tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubOOujO_-pQT"
   },
   "source": [
    "reshape 연산들을 `.view()`를 사용해서 구현하다보면 이해하기 어려운 에러를 보기도 합니다.\n",
    "그 이유는 tensor와 그 view가 내부적으로 구현된 방식과 관련이 있는데, [Edward Yang의 post](http://blog.ezyang.com/2019/05/pytorch-internals/)에서 이 문제를 잘 설명해주고 있습니다.\n",
    "\n",
    "여기서 알아두면 좋은 점은 이런 에러는 보통 `.view()`를 호출하기 전에 [.contiguous()](https://pytorch.org/docs/stable/generated/torch.Tensor.contiguous.html) 를 쓰거나, `.view()` 대신 [.reshape()](https://pytorch.org/docs/stable/generated/torch.reshape.html) 를 사용하면 해결할 수 있다는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4901,
     "status": "aborted",
     "timestamp": 1599236804374,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "YGC6NERq_CT9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'RuntimeError'> view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "x1 shape:  torch.Size([8, 3])\n",
      "x2 shape:  torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.randn(2, 3, 4)\n",
    "\n",
    "try:\n",
    "  # This sequence of reshape operations will crash\n",
    "  x1 = x0.transpose(1, 2).view(8, 3)\n",
    "except RuntimeError as e:\n",
    "  print(type(e), e)\n",
    "  \n",
    "# We can solve the problem using either .contiguous() or .reshape()\n",
    "x1 = x0.transpose(1, 2).contiguous().view(8, 3)\n",
    "x2 = x0.transpose(1, 2).reshape(8, 3)\n",
    "print('x1 shape: ', x1.shape)\n",
    "print('x2 shape: ', x2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJiiBxNE-X8g"
   },
   "source": [
    "#### 직접 구현하기\n",
    "\n",
    "함수 `reshape_practice`를 구현하세요.<br>\n",
    "입력은 0부터 23까지 순서대로 담고 있는 1차원 tensor x이며, 이를 reshape 연산을 이용해 아래와 같은 shape (3, 8)의 출력 tensor y로 변환해야 합니다:\n",
    "\n",
    "```\n",
    "y = tensor([[ 0,  1,  2,  3, 12, 13, 14, 15],\n",
    "            [ 4,  5,  6,  7, 16, 17, 18, 19],\n",
    "            [ 8,  9, 10, 11, 20, 21, 22, 23]])\n",
    "```\n",
    "\n",
    "Hint: 중간에 rank 3짜리 tensor를 만들어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4897,
     "status": "aborted",
     "timestamp": 1599236804375,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "8reAZGzFVTQ3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is x:\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23])\n",
      "Here is y:\n",
      "tensor([[ 0,  1,  2,  3, 12, 13, 14, 15],\n",
      "        [ 4,  5,  6,  7, 16, 17, 18, 19],\n",
      "        [ 8,  9, 10, 11, 20, 21, 22, 23]])\n",
      "Correct: True\n"
     ]
    }
   ],
   "source": [
    "from pytorch101 import reshape_practice\n",
    "\n",
    "x = torch.arange(24)\n",
    "print('Here is x:')\n",
    "print(x)\n",
    "y = reshape_practice(x)\n",
    "print('Here is y:')\n",
    "print(y)\n",
    "\n",
    "expected = [\n",
    "    [0, 1,  2,  3, 12, 13, 14, 15],\n",
    "    [4, 5,  6,  7, 16, 17, 18, 19],\n",
    "    [8, 9, 10, 11, 20, 21, 22, 23]]\n",
    "print('Correct:', y.tolist() == expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgcdvD1evxTQ"
   },
   "source": [
    "## Tensor operations\n",
    "자금까지는 tensor를 만드는법과 다루는 법에 대해서 배웠습니다. 하지만 우리가 PyTorch에서 tensor를 쓰는 가장 중요한 이유 중 하나는 바로 연산을 하기 위해서입니다.\n",
    "PyTorch는 아래와 같이 tensor에 대해 다양한 연산을 수행할 수 있는 기능을 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1BCVlPHZ4_Qz"
   },
   "source": [
    "### Elementwise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2wbN18E5CKI"
   },
   "source": [
    "기본적인 수학 함수들은 tensor의 각 원소에 대해 element 별(elementwise)로 동작합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4892,
     "status": "aborted",
     "timestamp": 1599236804375,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "QrMkbk535KRZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementwise sum:\n",
      "tensor([[ 6.,  8., 10., 12.]])\n",
      "tensor([[ 6.,  8., 10., 12.]])\n",
      "tensor([[ 6.,  8., 10., 12.]])\n",
      "\n",
      "Elementwise difference:\n",
      "tensor([[-4., -4., -4., -4.]])\n",
      "tensor([[-4., -4., -4., -4.]])\n",
      "tensor([[-4., -4., -4., -4.]])\n",
      "\n",
      "Elementwise product:\n",
      "tensor([[ 5., 12., 21., 32.]])\n",
      "tensor([[ 5., 12., 21., 32.]])\n",
      "tensor([[ 5., 12., 21., 32.]])\n",
      "\n",
      "Elementwise division\n",
      "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
      "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
      "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
      "\n",
      "Elementwise power\n",
      "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n",
      "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n",
      "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4]], dtype=torch.float32)\n",
    "y = torch.tensor([[5, 6, 7, 8]], dtype=torch.float32)\n",
    "\n",
    "# Elementwise sum; all give the same result\n",
    "print('Elementwise sum:')\n",
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "print(x.add(y))\n",
    "\n",
    "# Elementwise difference\n",
    "print('\\nElementwise difference:')\n",
    "print(x - y)\n",
    "print(torch.sub(x, y))\n",
    "print(x.sub(y))\n",
    "\n",
    "# Elementwise product\n",
    "print('\\nElementwise product:')\n",
    "print(x * y)\n",
    "print(torch.mul(x, y))\n",
    "print(x.mul(y))\n",
    "\n",
    "# Elementwise division\n",
    "print('\\nElementwise division')\n",
    "print(x / y)\n",
    "print(torch.div(x, y))\n",
    "print(x.div(y))\n",
    "\n",
    "# Elementwise power\n",
    "print('\\nElementwise power')\n",
    "print(x ** y)\n",
    "print(torch.pow(x, y))\n",
    "print(x.pow(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A6WwPJMYlYvN"
   },
   "source": [
    "PyTorch는 표준적인 수학 함수들도 제공합니다.  \n",
    "이 함수들은 `torch` 모듈의 함수로도, 그리고 `tensor`의 인스턴스 메서드로도 사용할 수 있습니다.  \n",
    "\n",
    "사용 가능한 수학 함수 전체 목록은 [공식 문서](https://pytorch.org/docs/stable/torch.html#pointwise-ops)에서 확인할 수 있습니다.  \n",
    "또한 `torch` 모듈의 많은 함수들은 [tensor 객체](https://pytorch.org/docs/stable/tensors.html)에서 대응되는 인스턴스 메서드를 가지고 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4888,
     "status": "aborted",
     "timestamp": 1599236804376,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "s87mjsnG58vR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square root:\n",
      "tensor([[1.0000, 1.4142, 1.7321, 2.0000]])\n",
      "tensor([[1.0000, 1.4142, 1.7321, 2.0000]])\n",
      "\n",
      "Trig functions:\n",
      "tensor([[ 0.8415,  0.9093,  0.1411, -0.7568]])\n",
      "tensor([[ 0.8415,  0.9093,  0.1411, -0.7568]])\n",
      "tensor([[ 0.5403, -0.4161, -0.9900, -0.6536]])\n",
      "tensor([[ 0.5403, -0.4161, -0.9900, -0.6536]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4]], dtype=torch.float32)\n",
    "\n",
    "print('Square root:')\n",
    "print(torch.sqrt(x))\n",
    "print(x.sqrt())\n",
    "\n",
    "print('\\nTrig functions:')\n",
    "print(torch.sin(x))\n",
    "print(x.sin())\n",
    "print(torch.cos(x))\n",
    "print(x.cos())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yDyH9USAuyZ-"
   },
   "source": [
    "### Reduction operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbHP9SpZHoMO"
   },
   "source": [
    "지금까지는 `tensor`에 대해 elementwise로 동작하는 기본 산술 연산을 살펴봤습니다.<br>\n",
    "하지만 `tensor`의 일부 또는 전체에 대해 합(sum) 같은 연산을 수행해야하는 경우도 있겠죠.\n",
    "이런 연산을 **reduction 연산**이라고 합니다.  \n",
    "\n",
    "앞서 본 elementwise 연산과 마찬가지로, 대부분의 reduction 연산은 `torch` 모듈의 함수와 `tensor` 객체의 인스턴스 메서드 두 가지 방식으로 모두 사용할 수 있습니다.  \n",
    "\n",
    "가장 단순한 reduction 연산은 합(sum)입니다.  \n",
    "이를 위해 [`.sum()`](https://pytorch.org/docs/stable/generated/torch.Tensor.sum.html) 메서드(또는 [`torch.sum`](https://pytorch.org/docs/stable/generated/torch.sum.html))를 사용할 수 있습니다.  \n",
    "이 함수는 `tensor` 전체를 줄이거나, `dim` 인자를 사용해 특정 차원에 대해서만 줄일 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4883,
     "status": "aborted",
     "timestamp": 1599236804376,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "LlmsYJWUE2r3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Sum over entire tensor:\n",
      "tensor(21.)\n",
      "tensor(21.)\n",
      "\n",
      "Sum over the first dimension:\n",
      "tensor([5., 7., 9.])\n",
      "tensor([5., 7., 9.])\n",
      "\n",
      "Sum over the second dimension:\n",
      "tensor([ 6., 15.])\n",
      "tensor([ 6., 15.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], \n",
    "                  [4, 5, 6]], dtype=torch.float32)\n",
    "print('Original tensor:')\n",
    "print(x)\n",
    "\n",
    "print('\\nSum over entire tensor:')\n",
    "print(torch.sum(x))\n",
    "print(x.sum())\n",
    "\n",
    "# We can sum over the first dimension:\n",
    "print('\\nSum over the first dimension:')\n",
    "print(torch.sum(x, dim=0))\n",
    "print(x.sum(dim=0))\n",
    "\n",
    "# Sum over the second dimension:\n",
    "print('\\nSum over the second dimension:')\n",
    "print(torch.sum(x, dim=1))\n",
    "print(x.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduction 연산에서 자주 헷갈리는 부분 중 하나가 `dim` 인자입니다.  \n",
    "예를들어, 행을 기준으로 합을 구하는 것과 열을 기준으로 합을 구하는 것은 어떻게 다를까를 생각해보세요.\n",
    "\n",
    "이를 가장 쉽게 기억하는 방법은 관련된 `tensor`의 shape를 생각하는 것입니다.  \n",
    "`dim=d`로 합을 구하면, 입력에서 인덱스 `d`에 해당하는 차원이 출력 `tensor`의 shape에서 **사라집니다**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:  torch.Size([3, 4, 5, 6])\n",
      "x.sum(dim=0).shape:  torch.Size([4, 5, 6])\n",
      "x.sum(dim=1).shape:  torch.Size([3, 5, 6])\n",
      "x.sum(dim=2).shape:  torch.Size([3, 4, 6])\n",
      "x.sum(dim=3).shape:  torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of shape (3, 4, 5, 6)\n",
    "x = torch.randn(3, 4, 5, 6)\n",
    "print('x.shape: ', x.shape)\n",
    "\n",
    "# Summing over dim=0 eliminates the dimension at index 0 (of size 3):\n",
    "print('x.sum(dim=0).shape: ', x.sum(dim=0).shape)\n",
    "\n",
    "# Summing with dim=1 eliminates the dimension at index 1 (of size 4):\n",
    "print('x.sum(dim=1).shape: ', x.sum(dim=1).shape)\n",
    "\n",
    "# Summing with dim=2 eliminates the dimension at index 2 (of size 5):\n",
    "print('x.sum(dim=2).shape: ', x.sum(dim=2).shape)\n",
    "\n",
    "# Summing with dim=3 eliminates the dimension at index 3 (of size 6):\n",
    "print('x.sum(dim=3).shape: ', x.sum(dim=3).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzKio_3Quz5a"
   },
   "source": [
    "유용한 다른 reduction 연산으로는 [`mean`](https://pytorch.org/docs/stable/generated/torch.mean.html), [`min`](https://pytorch.org/docs/stable/generated/torch.min.html), [`max`](https://pytorch.org/docs/stable/generated/torch.max.html) 등이 있습니다.  \n",
    "모든 reduction 연산의 전체 목록은 [공식 문서](https://pytorch.org/docs/stable/torch.html#reduction-ops)에서 확인할 수 있습니다.  \n",
    "\n",
    "일부 reduction 연산은 두 개 이상의 값을 반환하기도 합니다.  \n",
    "예를 들어 `min`은 지정한 차원에서의 최소값뿐 아니라, 그 최소값이 위치한 인덱스도 함께 반환합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4878,
     "status": "aborted",
     "timestamp": 1599236804376,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "TFD7aT54H4ik"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[2., 4., 3., 5.],\n",
      "        [3., 3., 5., 2.]]) torch.Size([2, 4])\n",
      "\n",
      "Overall minimum:  tensor(2.)\n",
      "\n",
      "Minimum along each column:\n",
      "values: tensor([2., 3., 3., 2.])\n",
      "idxs: tensor([0, 1, 0, 1])\n",
      "\n",
      "Minimum along each row:\n",
      "values: tensor([2., 2.])\n",
      "idxs: tensor([0, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[2, 4, 3, 5], [3, 3, 5, 2]], dtype=torch.float32)\n",
    "print('Original tensor:')\n",
    "print(x, x.shape)\n",
    "\n",
    "# Finding the overall minimum only returns a single value\n",
    "print('\\nOverall minimum: ', x.min())\n",
    "\n",
    "# Compute the minimum along each column; we get both the value and location:\n",
    "# The minimum of the first column is 2, and it appears at index 0;\n",
    "# the minimum of the second column is 3 and it appears at index 1; etc\n",
    "col_min_vals, col_min_idxs = x.min(dim=0)\n",
    "print('\\nMinimum along each column:')\n",
    "print('values:', col_min_vals)\n",
    "print('idxs:', col_min_idxs)\n",
    "\n",
    "# Compute the minimum along each row; we get both the value and the minimum\n",
    "row_min_vals, row_min_idxs = x.min(dim=1)\n",
    "print('\\nMinimum along each row:')\n",
    "print('values:', row_min_vals)\n",
    "print('idxs:', row_min_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XFwYRESoFr4t"
   },
   "source": [
    "reduction 연산은 `tensor`의 rank를 *줄입니다*. 즉, reduction이 수행된 차원은 출력의 shape에서 사라집니다.<br>\n",
    "만약 `keepdim=True`를 전달하면 해당 차원은 제거되지 않고, 대신 그 차원의 크기가 1인 상태로 유지됩니다.  \n",
    "\n",
    "다차원 `tensor`를 다룰 때는 \"행(row)\"이나 \"열(column)\"을 기준으로 생각하면 헷갈릴 수 있습니다.  \n",
    "대신 각 연산이 끝난 뒤 어떤 shape이 나올지를 떠올리는 것이 훨씬 유용합니다.  \n",
    "예를 들어 아래와 같은 코드를 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4874,
     "status": "aborted",
     "timestamp": 1599236804377,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "sjcAveyJFqm7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 3, 64, 64])\n",
      "torch.Size([128, 3, 64, 64])\n",
      "torch.Size([128, 3, 64])\n",
      "torch.Size([128, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of shape (128, 10, 3, 64, 64)\n",
    "x = torch.randn(128, 10, 3, 64, 64)\n",
    "print(x.shape)\n",
    "\n",
    "# Take the mean over dimension 1; shape is now (128, 3, 64, 64)\n",
    "x = x.mean(dim=1)\n",
    "print(x.shape)\n",
    "\n",
    "# Take the sum over dimension 2; shape is now (128, 3, 64)\n",
    "x = x.sum(dim=2)\n",
    "print(x.shape)\n",
    "\n",
    "# Take the mean over dimension 1, but keep the dimension from being eliminated\n",
    "# by passing keepdim=True; shape is now (128, 1, 64)\n",
    "x = x.mean(dim=1, keepdim=True)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXMp4tcM0Q_E"
   },
   "source": [
    "#### 직접 구현하기\n",
    "함수 `zero_row_min`을 구현하세요.<br>\n",
    "이 함수는 각 행(row)에서 최소값을 찾아 **그 위치의 값을 0으로 설정**해야 합니다.  \n",
    "reduction과 인덱싱 연산을 사용하고, **명시적인 반복문은 사용하지 마세요**.\n",
    "\n",
    "힌트: [`clone`](https://pytorch.org/docs/stable/generated/torch.Tensor.clone.html), [`argmin`](https://pytorch.org/docs/stable/generated/torch.Tensor.argmin.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4868,
     "status": "aborted",
     "timestamp": 1599236804377,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "aaJzt-Y62blF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is x0:\n",
      "tensor([[10, 20, 30],\n",
      "        [ 2,  5,  1]])\n",
      "Here is y0:\n",
      "tensor([[ 0, 20, 30],\n",
      "        [ 2,  5,  0]])\n",
      "y0 correct:  True\n",
      "\n",
      "Here is x1:\n",
      "tensor([[ 2,  5, 10, -1],\n",
      "        [ 1,  3,  2,  4],\n",
      "        [ 5,  6,  2, 10]])\n",
      "Here is y1:\n",
      "tensor([[ 2,  5, 10,  0],\n",
      "        [ 0,  3,  2,  4],\n",
      "        [ 5,  6,  0, 10]])\n",
      "y1 correct:  True\n"
     ]
    }
   ],
   "source": [
    "from pytorch101 import zero_row_min\n",
    "\n",
    "x0 = torch.tensor([[10, 20, 30], [2, 5, 1]])\n",
    "print('Here is x0:')\n",
    "print(x0)\n",
    "y0 = zero_row_min(x0)\n",
    "print('Here is y0:')\n",
    "print(y0)\n",
    "expected = [[0, 20, 30], [2, 5, 0]]\n",
    "y0_correct = torch.is_tensor(y0) and y0.tolist() == expected\n",
    "print('y0 correct: ', y0_correct)\n",
    "\n",
    "x1 = torch.tensor([[2, 5, 10, -1], [1, 3, 2, 4], [5, 6, 2, 10]])\n",
    "print('\\nHere is x1:')\n",
    "print(x1)\n",
    "y1 = zero_row_min(x1)\n",
    "print('Here is y1:')\n",
    "print(y1)\n",
    "expected = [[2, 5, 10, 0], [0, 3, 2, 4], [5, 6, 0, 10]]\n",
    "y1_correct = torch.is_tensor(y1) and y1.tolist() == expected\n",
    "print('y1 correct: ', y1_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRyLyXU2u29N"
   },
   "source": [
    "### Matrix operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7DwjbapG6MM_"
   },
   "source": [
    "MATLAB과 달리 `*` 연산자는 elementwise 곱셈을 의미하며, 행렬 곱셈이 아닙니다.  \n",
    "PyTorch는 다양한 선형대수 함수를 제공하며, 벡터와 행렬 곱을 여러 방식으로 계산할 수 있습니다.  \n",
    "가장 자주 사용되는 것들은 다음과 같습니다:\n",
    "\n",
    "- [`torch.dot`](https://pytorch.org/docs/stable/generated/torch.dot.html): 벡터의 내적(inner product)을 계산\n",
    "- [`torch.mm`](https://pytorch.org/docs/stable/generated/torch.mm.html): 행렬-행렬 곱\n",
    "- [`torch.mv`](https://pytorch.org/docs/stable/generated/torch.mv.html): 행렬-벡터 곱\n",
    "- [`torch.addmm`](https://pytorch.org/docs/stable/generated/torch.addmm.html) / [`torch.addmv`](https://pytorch.org/docs/stable/generated/torch.addmv.html): 행렬-행렬, 행렬-벡터 곱 후 bias 더하기\n",
    "- [`torch.bmm`](https://pytorch.org/docs/stable/generated/torch.bmm.html) / [`torch.baddmm`](https://pytorch.org/docs/stable/generated/torch.baddbmm.html): 각각 `torch.mm`과 `torch.addmm`의 배치(batch) 버전\n",
    "- [`torch.matmul`](https://pytorch.org/docs/stable/generated/torch.matmul.html): 입력의 rank에 따라 다른 연산을 수행하는 일반적인 행렬 곱. numpy의 `np.dot`과 유사하지만 다소 혼란스러울 수 있음.\n",
    "\n",
    "사용 가능한 선형대수 연산자의 전체 목록은 [공식 문서](https://pytorch.org/docs/stable/torch.html#blas-and-lapack-operations)에서 확인할 수 있습니다.  \n",
    "이 함수들은 모두 `Tensor` 인스턴스 메서드로도 제공되며, 예를 들어 `torch.dot` 대신 [`Tensor.dot`](https://pytorch.org/docs/stable/generated/torch.Tensor.dot.html)처럼 쓸 수 있습니다.  \n",
    "\n",
    "아래는 `torch.dot`을 이용해 벡터 내적을 계산하는 예시입니다.  \n",
    "앞서 살펴본 다른 수학 연산자들과 마찬가지로, 대부분의 선형대수 연산자도 `torch` 모듈 함수와 `tensor` 인스턴스 메서드 두 가지 방식으로 사용할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4864,
     "status": "aborted",
     "timestamp": 1599236804378,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "TRUYW2as6ZCh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot products:\n",
      "tensor(219.)\n",
      "tensor(219.)\n",
      "1D tensors expected, but got 2D and 2D tensors\n",
      "\n",
      "Matrix-matrix product:\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([9,10], dtype=torch.float32)\n",
    "w = torch.tensor([11, 12], dtype=torch.float32)\n",
    "\n",
    "# Inner product of vectors\n",
    "print('Dot products:')\n",
    "print(torch.dot(v, w))\n",
    "print(v.dot(w))\n",
    "\n",
    "# dot only works for vectors -- it will give an error for tensors of rank > 1\n",
    "x = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
    "y = torch.tensor([[5,6],[7,8]], dtype=torch.float32)\n",
    "try:\n",
    "  print(x.dot(y))\n",
    "except RuntimeError as e:\n",
    "  print(e)\n",
    "  \n",
    "# Instead we use mm for matrix-matrix products:\n",
    "print('\\nMatrix-matrix product:')\n",
    "print(torch.mm(x, y))\n",
    "print(x.mm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-eqQJ5IUjtNT"
   },
   "source": [
    "#### 직접 구현하기\n",
    "함수 `batched_matrix_multiply`를 확인하세요.\n",
    "\n",
    "두 가지 inner function `batched_matrix_multiply_loop`와 `batched_matrix_multiply_noloop`를 구현해야 합니다.  \n",
    "첫 번째는 배치 dim을 따라 **명시적인 Python 루프**를 사용해 배치 행렬 곱을 계산해야 하고,  \n",
    "두 번째는 **명시적 루프 없이** PyTorch의 **단일 연산**으로 배치 행렬 곱을 수행해야 합니다.\n",
    "\n",
    "힌트: [`torch.stack`](https://pytorch.org/docs/master/generated/torch.stack.html), [`torch.bmm`](https://pytorch.org/docs/stable/generated/torch.bmm.html)가 도움이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4854,
     "status": "aborted",
     "timestamp": 1599236804379,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "sZD1VQHKVTRQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1 difference:  0.0\n",
      "z1 difference within tolerance:  True\n",
      "\n",
      "z2 difference:  0.0\n",
      "z2 difference within tolerance:  True\n"
     ]
    }
   ],
   "source": [
    "from pytorch101 import batched_matrix_multiply\n",
    "\n",
    "B, N, M, P = 2, 3, 5, 4\n",
    "x = torch.randn(B, N, M)\n",
    "y = torch.randn(B, M, P)\n",
    "z_expected = torch.stack([x[0] @ y[0], x[1] @ y[1]])\n",
    "\n",
    "# The two may not return exactly the same result; different linear algebra\n",
    "# routines often return slightly different results due to the fact that\n",
    "# floating-point math is non-exact and non-associative.\n",
    "z1 = batched_matrix_multiply(x, y, use_loop=True)\n",
    "z1_diff = (z1 - z_expected).abs().max().item()\n",
    "print('z1 difference: ', z1_diff)\n",
    "print('z1 difference within tolerance: ', z1_diff < 1e-6)\n",
    "\n",
    "z2 = batched_matrix_multiply(x, y, use_loop=False)\n",
    "z2_diff = (z2 - z_expected).abs().max().item()\n",
    "print('\\nz2 difference: ', z2_diff)\n",
    "print('z2 difference within tolerance: ', z2_diff < 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mbCVOr2sVTRR"
   },
   "source": [
    "### 직접 구현하기: Vectorization (벡터화)\n",
    "Pytorch 코드를 효율적으로 구현하고 싶다면 최대한 코드에서 **명시적인 Python 루프를 피하고**, 반복은 PyTorch 연산자에 맡기는게 좋습니다.<br>\n",
    "이렇게 쓰는 방식을 **vectorization (벡터화)** 이라고 합니다.  \n",
    "이 방식은 Python 인터프리터의 오버헤드를 줄이고 계산을 더 잘 병렬화할 수 있어 보통 훨씬 빠르게 동작합니다.  \n",
    "특히 Python은 iterative loop가 매우 느리기 때문에 C++과 같은 저수준 언어보다 더욱 vectorization이 중요합니다. 따라서, 가능한 한 벡터화된 코드를 작성하는 습관을 들이면 좋습니다.\n",
    "\n",
    "아래 코드를 실행해 `batched_matrix_multiply`의 실행 속도를 비교해 보세요.  \n",
    "`use_loop=True`와 `use_loop=False` 두 경우를 측정해 차이를 확인합니다. (참고로 CPU보다 GPU에서 속도 차이가 훨씬 많이 나게 됩니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4849,
     "status": "aborted",
     "timestamp": 1599236804379,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "a-acTIOpVTRR"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch101 import batched_matrix_multiply\n",
    "\n",
    "N, M, P = 64, 64, 64\n",
    "loop_times = []\n",
    "no_loop_times = []\n",
    "no_loop_speedup = []\n",
    "Bs = list(range(4, 128, 4))\n",
    "num_trials = 20\n",
    "for B in Bs:\n",
    "    loop_trials = []\n",
    "    no_loop_trials = []\n",
    "    for trial in range(num_trials):\n",
    "        x = torch.randn(B, N, M)\n",
    "        y = torch.randn(B, M, P)\n",
    "        t0 = time.time()\n",
    "        z1 = batched_matrix_multiply(x, y, use_loop=True)\n",
    "        t1 = time.time()\n",
    "        z2 = batched_matrix_multiply(x, y, use_loop=False)\n",
    "        t2 = time.time()\n",
    "        loop_trials.append(t1 - t0)\n",
    "        no_loop_trials.append(t2 - t1)\n",
    "    loop_mean = torch.tensor(loop_trials).mean().item()\n",
    "    no_loop_mean = torch.tensor(no_loop_trials).mean().item()\n",
    "    loop_times.append(loop_mean)\n",
    "    no_loop_times.append(no_loop_mean)\n",
    "    no_loop_speedup.append(loop_mean / no_loop_mean)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(Bs, loop_times, 'o-', label='use_loop=True')\n",
    "plt.plot(Bs, no_loop_times, 'o-', label='use_loop=False')\n",
    "plt.xlabel('Batch size B')\n",
    "plt.ylabel('Runtime (s)')\n",
    "plt.legend(fontsize=14)\n",
    "plt.title('Loop vs Vectorized speeds')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(Bs, no_loop_speedup, '-o')\n",
    "plt.title('Vectorized speedup')\n",
    "plt.xlabel('Batch size B')\n",
    "plt.ylabel('Vectorized speedup')\n",
    "\n",
    "plt.gcf().set_size_inches(12, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UISn2pcf9QjY"
   },
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTj6f8VN9UZg"
   },
   "source": [
    "Broadcasting은 서로 다른 shape을 가진 `tensor`들 사이에서도 산술 연산을 가능하게 해주는 편리한 방법입니다.  \n",
    "보통은 작은 `tensor`와 큰 `tensor`가 있을 때, 작은 `tensor`를 여러 번 확장해 큰 `tensor`에 연산을 적용하고 싶을 때 사용됩니다.  \n",
    "\n",
    "예를 들어, 어떤 `tensor`의 각 row에 동일한 상수 벡터를 더하고 싶다고 가정해 봅시다.  \n",
    "이 경우 다음과 같이 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4845,
     "status": "aborted",
     "timestamp": 1599236804380,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "kF0Dhzlu9fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  2,  4],\n",
      "        [ 5,  5,  7],\n",
      "        [ 8,  8, 10],\n",
      "        [11, 11, 13]])\n"
     ]
    }
   ],
   "source": [
    "# We will add the vector v to each row of the matrix x,\n",
    "# storing the result in the matrix y\n",
    "x = torch.tensor([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
    "v = torch.tensor([1, 0, 1])\n",
    "y = torch.zeros_like(x)   # Create an empty matrix with the same shape as x\n",
    "\n",
    "# Add the vector v to each row of the matrix x with an explicit loop\n",
    "for i in range(4):\n",
    "    y[i, :] = x[i, :] + v\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gXpoBKE9vp7"
   },
   "source": [
    "이 방법도 잘 동작은 합니다만, `x`가 아주 클 경우, Python에서 명시적으로 루프를 돌면 느릴 수 있습니다.  \n",
    "사실 `x`의 각 행에 벡터 `v`를 더하는 것은, `v`를 여러 번 세로로 쌓아 만든 `vv`라는 `tensor`를 만든 다음, `x`와 `vv`를 원소별로 더하는 것과 같습니다.  \n",
    "이 접근은 다음처럼 구현할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4839,
     "status": "aborted",
     "timestamp": 1599236804380,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "_2_5cKeu94c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [1, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "vv = v.repeat((4, 1))  # Stack 4 copies of v on top of each other\n",
    "print(vv)              # Prints \"[[1 0 1]\n",
    "                       #          [1 0 1]\n",
    "                       #          [1 0 1]\n",
    "                       #          [1 0 1]]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4834,
     "status": "aborted",
     "timestamp": 1599236804380,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "1KiRj23p-QIs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  2,  4],\n",
      "        [ 5,  5,  7],\n",
      "        [ 8,  8, 10],\n",
      "        [11, 11, 13]])\n"
     ]
    }
   ],
   "source": [
    "y = x + vv  # Add x and vv elementwise\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7NNlSsHBKib"
   },
   "source": [
    "PyTorch의 broadcasting을 사용하면 `v`를 여러 번 복사해 만들지 않고도 같은 계산을 수행할 수 있습니다.  \n",
    "broadcasting을 활용한 버전은 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4829,
     "status": "aborted",
     "timestamp": 1599236804381,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "2jIiZc-ABBnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  2,  4],\n",
      "        [ 5,  5,  7],\n",
      "        [ 8,  8, 10],\n",
      "        [11, 11, 13]])\n"
     ]
    }
   ],
   "source": [
    "# We will add the vector v to each row of the matrix x,\n",
    "# storing the result in the matrix y\n",
    "x = torch.tensor([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
    "v = torch.tensor([1, 0, 1])\n",
    "y = x + v  # Add v to each row of x using broadcasting\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HuUBX8YnBSIG"
   },
   "source": [
    "`y = x + v`라는 한 줄이 동작하는 이유는, `x`의 shape이 (4, 3)이고 `v`의 shape이 (3,)임에도 불구하고 broadcasting이 적용되기 때문입니다.  \n",
    "이 연산은 마치 `v`가 (4, 3) 모양으로 확장되어 각 행이 `v`의 복사본인 것처럼 작동하며, 원소별 합이 수행됩니다.  \n",
    "\n",
    "두 `tensor`가 broadcasting될 때는 다음 규칙을 따릅니다:\n",
    "\n",
    "1. 두 `tensor`의 rank가 다르면, 낮은 rank의 shape 앞에 1을 붙여 길이를 맞춘다.  \n",
    "2. 특정 차원에서 두 `tensor`의 크기가 같거나, 둘 중 하나가 1이면 두 `tensor`는 그 차원에서 *호환 가능(compatible)* 하다.  \n",
    "3. 모든 차원에서 호환 가능하다면 두 `tensor`는 함께 broadcasting될 수 있다.  \n",
    "4. broadcasting된 후 각 `tensor`는 두 입력 `tensor` shape의 원소별 최댓값과 동일한 shape을 가진 것처럼 동작한다.  \n",
    "5. 어떤 차원에서 한 `tensor`의 크기가 1이고 다른 `tensor`의 크기가 1보다 크다면, 크기가 1인 `tensor`는 그 차원에서 복사된 것처럼 동작한다.  \n",
    "\n",
    "이 설명이 잘 이해되지 않는다면 [공식 문서](https://pytorch.org/docs/stable/notes/broadcasting.html)의 설명을 참고하세요.  \n",
    "\n",
    "Broadcasting은 보통 PyTorch 연산자 내부에서 암묵적으로 일어나지만, [`torch.broadcast_tensors`](https://pytorch.org/docs/stable/generated/torch.broadcast_tensors.html#torch.broadcast_tensors)를 사용해 명시적으로 수행할 수도 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4824,
     "status": "aborted",
     "timestamp": 1599236804381,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "YIlIBao3VTRc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is x (before broadcasting):\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "x.shape:  torch.Size([4, 3])\n",
      "\n",
      "Here is v (before broadcasting):\n",
      "tensor([1, 0, 1])\n",
      "v.shape:  torch.Size([3])\n",
      "Here is xx (after) broadcasting):\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "xx.shape:  torch.Size([4, 3])\n",
      "\n",
      "Here is vv (after broadcasting):\n",
      "tensor([[1, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [1, 0, 1]])\n",
      "vv.shape:  torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "v = torch.tensor([1, 0, 1])\n",
    "print('Here is x (before broadcasting):')\n",
    "print(x)\n",
    "print('x.shape: ', x.shape)\n",
    "print('\\nHere is v (before broadcasting):')\n",
    "print(v)\n",
    "print('v.shape: ', v.shape)\n",
    "\n",
    "xx, vv = torch.broadcast_tensors(x, v)\n",
    "print('Here is xx (after) broadcasting):')\n",
    "print(xx)\n",
    "print('xx.shape: ', x.shape)\n",
    "print('\\nHere is vv (after broadcasting):')\n",
    "print(vv)\n",
    "print('vv.shape: ', vv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWXtBo6eVTRf"
   },
   "source": [
    "broadcasting이 적용된 후에도 `x`는 변하지 않지만, `v`는 shape 앞에 새로운 차원이 추가되고 `x`와 같은 shape을 갖도록 복제됩니다.  \n",
    "이제 두 `tensor`의 shape가 같아졌으므로 원소별 덧셈을 수행할 수 있습니다.  \n",
    "\n",
    "모든 원소별(elementwise) 함수들은 broadcasting을 지원합니다.  \n",
    "일부 원소별이 아닌 함수(예: 선형대수 함수)들도 broadcasting을 지원하며, 특정 함수가 broadcasting을 지원하는지는 문서를 확인해야 합니다.  \n",
    "예를 들어 [`torch.mm`](https://pytorch.org/docs/stable/generated/torch.mm.html)은 broadcasting을 지원하지 않지만, [`torch.matmul`](https://pytorch.org/docs/stable/generated/torch.matmul.html)은 지원합니다.  \n",
    "\n",
    "broadcasting을 활용하면 다양한 연산을 쉽게 구현할 수 있습니다.  \n",
    "예를 들어, 벡터의 외적(outer product)을 계산할 수도 있습니다:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4820,
     "status": "aborted",
     "timestamp": 1599236804382,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "_W-k7-hpCwlT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  5],\n",
      "        [ 8, 10],\n",
      "        [12, 15]])\n"
     ]
    }
   ],
   "source": [
    "# Compute outer product of vectors\n",
    "v = torch.tensor([1, 2, 3])  # v has shape (3,)\n",
    "w = torch.tensor([4, 5])     # w has shape (2,)\n",
    "# To compute an outer product, we first reshape v to be a column\n",
    "# vector of shape (3, 1); we can then broadcast it against w to yield\n",
    "# an output of shape (3, 2), which is the outer product of v and w:\n",
    "print(v.view(3, 1) * w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6a9EcX20moP_"
   },
   "source": [
    "행렬의 각 행(row)에 벡터를 더할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4815,
     "status": "aborted",
     "timestamp": 1599236804382,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "9bhmBiwcDF1B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the matrix:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Here is the vector:\n",
      "tensor([1, 2, 3])\n",
      "\n",
      "Add the vector to each row of the matrix:\n",
      "tensor([[2, 4, 6],\n",
      "        [5, 7, 9]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # x has shape (2, 3)\n",
    "v = torch.tensor([1, 2, 3])               # v has shape (3,)\n",
    "print('Here is the matrix:')\n",
    "print(x)\n",
    "print('\\nHere is the vector:')\n",
    "print(v)\n",
    "\n",
    "# x has shape (2, 3) and v has shape (3,) so they broadcast to (2, 3),\n",
    "# giving the following matrix:\n",
    "print('\\nAdd the vector to each row of the matrix:')\n",
    "print(x + v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYloJIvmm_Me"
   },
   "source": [
    "행렬의 각 열(column)에 벡터를 더할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4811,
     "status": "aborted",
     "timestamp": 1599236804383,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "TDTFKACqDK22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the matrix:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Here is the vector:\n",
      "tensor([4, 5])\n",
      "\n",
      "Add the vector to each column of the matrix:\n",
      "tensor([[ 5,  6,  7],\n",
      "        [ 9, 10, 11]])\n",
      "tensor([[ 5,  6,  7],\n",
      "        [ 9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # x has shape (2, 3)\n",
    "w = torch.tensor([4, 5])                  # w has shape (2,)\n",
    "print('Here is the matrix:')\n",
    "print(x)\n",
    "print('\\nHere is the vector:')\n",
    "print(w)\n",
    "\n",
    "# x has shape (2, 3) and w has shape (2,). We reshape w to (2, 1);\n",
    "# then when we add the two the result broadcasts to (2, 3):\n",
    "print('\\nAdd the vector to each column of the matrix:')\n",
    "print(x + w.view(-1, 1))\n",
    "\n",
    "# Another solution is the following:\n",
    "# 1. Transpose x so it has shape (3, 2)\n",
    "# 2. Since w has shape (2,), adding will broadcast to (3, 2)\n",
    "# 3. Transpose the result, resulting in a shape (2, 3)\n",
    "print((x.t() + w).t())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9717YmBBpBfr"
   },
   "source": [
    "`tensor`에 여러 상수를 곱할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4806,
     "status": "aborted",
     "timestamp": 1599236804383,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "4UjWDp_XDc_-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the matrix:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Here is the vector:\n",
      "tensor([  1,  10,  11, 100])\n",
      "\n",
      "Multiply x by a set of constants:\n",
      "tensor([[[  1,   2,   3],\n",
      "         [  4,   5,   6]],\n",
      "\n",
      "        [[ 10,  20,  30],\n",
      "         [ 40,  50,  60]],\n",
      "\n",
      "        [[ 11,  22,  33],\n",
      "         [ 44,  55,  66]],\n",
      "\n",
      "        [[100, 200, 300],\n",
      "         [400, 500, 600]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])  # x has shape (2, 3)\n",
    "c = torch.tensor([1, 10, 11, 100])        # c has shape (4)\n",
    "print('Here is the matrix:')\n",
    "print(x)\n",
    "print('\\nHere is the vector:')\n",
    "print(c)\n",
    "\n",
    "# We do the following:\n",
    "# 1. Reshape c from (4,) to (4, 1, 1)\n",
    "# 2. x has shape (2, 3). Since they have different ranks, when we multiply the\n",
    "#    two, x behaves as if its shape were (1, 2, 3)\n",
    "# 3. The result of the broadcast multiplication between tensor of shape\n",
    "#    (4, 1, 1) and (1, 2, 3) has shape (4, 2, 3)\n",
    "# 4. The result y has shape (4, 2, 3), and y[i] (shape (2, 3)) is equal to\n",
    "#    c[i] * x\n",
    "y = c.view(-1, 1, 1) * x\n",
    "print('\\nMultiply x by a set of constants:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2EHXFBFq1ea"
   },
   "source": [
    "#### 직접 구현하기\n",
    "`normalize_columns`를 구현하세요.  \n",
    "이 함수는 행렬의 각 열(column)을 정규화해야 합니다.  \n",
    "즉, 각 열의 평균(mean)과 표준편차(std)를 구한 뒤, 각 원소에서 평균을 빼고 표준편차로 나눠야 합니다.  \n",
    "\n",
    "예시:  \n",
    "```\n",
    "x = [[ 0,  30,  600],\n",
    "     [ 1,  10,  200],\n",
    "     [-1,  20,  400]]\n",
    "```\n",
    "- 첫 번째 열의 mean = 0, std = 1  \n",
    "- 두 번째 열의 mean = 20, std = 10  \n",
    "- 세 번째 열의 mean = 400, std = 200  \n",
    "\n",
    "정규화 후 결과는 다음과 같아야 합니다:  \n",
    "```\n",
    "y = [[ 0,  1,  1],\n",
    "     [ 1, -1, -1],\n",
    "     [-1,  0,  0]]\n",
    "```\n",
    "\n",
    "참고: 스칼라 $x_1,\\ldots,x_M$에 대해 평균 $\\mu$와 표준편차 $\\sigma$는 다음과 같이 정의됩니다:\n",
    "\n",
    "$$\\mu=\\frac{1}{M}\\sum_{i=1}^M x_i \\hspace{4pc} \\sigma = \\sqrt{\\frac{1}{M-1}\\sum_{i=1}^M(x_i-\\mu)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4801,
     "status": "aborted",
     "timestamp": 1599236804383,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "rVh1DMqMr3zl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is x:\n",
      "tensor([[  0.,  30., 600.],\n",
      "        [  1.,  10., 200.],\n",
      "        [ -1.,  20., 400.]])\n",
      "Here is y:\n",
      "tensor([[ 0.,  1.,  1.],\n",
      "        [ 1., -1., -1.],\n",
      "        [-1.,  0.,  0.]])\n",
      "y correct:  True\n",
      "x unchanged:  True\n"
     ]
    }
   ],
   "source": [
    "from pytorch101 import normalize_columns\n",
    "\n",
    "x = torch.tensor([[0., 30., 600.], [1., 10., 200.], [-1., 20., 400.]])\n",
    "y = normalize_columns(x)\n",
    "print('Here is x:')\n",
    "print(x)\n",
    "print('Here is y:')\n",
    "print(y)\n",
    "\n",
    "x_expected = [[0., 30., 600.], [1., 10., 200.], [-1., 20., 400.]]\n",
    "y_expected = [[0., 1., 1.], [1., -1., -1.], [-1., 0., 0.]]\n",
    "y_correct = y.tolist() == y_expected\n",
    "x_correct = x.tolist() == x_expected\n",
    "print('y correct: ', y_correct)\n",
    "print('x unchanged: ', x_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NlJs-yN4VTRp"
   },
   "source": [
    "### Out-of-place vs In-place 연산자\n",
    "PyTorch 연산자는 보통 두 가지로 나눌 수 있습니다:  \n",
    "- **Out-of-place 연산자:** 새로운 `tensor`를 반환합니다. 대부분의 PyTorch 연산자가 여기에 해당합니다.  \n",
    "- **In-place 연산자:** 입력 `tensor` 자체를 수정하고 반환합니다. 인스턴스 메서드 이름이 밑줄(`_`)로 끝나면(`add_()` 등) in-place 연산자입니다.  \n",
    "  또한 `torch` 네임스페이스의 연산자들은 `out=` 키워드 인자를 사용해 in-place 동작을 시킬 수 있습니다.  \n",
    "\n",
    "예를 들어:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4797,
     "status": "aborted",
     "timestamp": 1599236804384,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "lnwGzmU9VTRp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-place addition:\n",
      "Before addition:\n",
      "x:  tensor([1, 2, 3])\n",
      "y:  tensor([3, 4, 5])\n",
      "\n",
      "After addition (x and y unchanged):\n",
      "x:  tensor([1, 2, 3])\n",
      "y:  tensor([3, 4, 5])\n",
      "z:  tensor([4, 6, 8])\n",
      "z is x:  False\n",
      "z is y:  False\n",
      "\n",
      "\n",
      "In-place Addition:\n",
      "Before addition:\n",
      "x:  tensor([1, 2, 3])\n",
      "y:  tensor([3, 4, 5])\n",
      "\n",
      "After addition (x is modified):\n",
      "x:  tensor([4, 6, 8])\n",
      "y:  tensor([3, 4, 5])\n",
      "z:  tensor([4, 6, 8])\n",
      "z is x:  False\n",
      "z is y:  False\n"
     ]
    }
   ],
   "source": [
    "# Out-of-place addition creates and returns a new tensor without modifying the inputs:\n",
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([3, 4, 5])\n",
    "print('Out-of-place addition:')\n",
    "print('Before addition:')\n",
    "print('x: ', x)\n",
    "print('y: ', y)\n",
    "z = x.add(y)  # Same as z = x + y or z = torch.add(x, y)\n",
    "print('\\nAfter addition (x and y unchanged):')\n",
    "print('x: ', x)\n",
    "print('y: ', y)\n",
    "print('z: ', z)\n",
    "print('z is x: ', z is x)\n",
    "print('z is y: ', z is y)\n",
    "\n",
    "# In-place addition modifies the input tensor:\n",
    "print('\\n\\nIn-place Addition:')\n",
    "print('Before addition:')\n",
    "print('x: ', x)\n",
    "print('y: ', y)\n",
    "x.add_(y)  # Same as x += y or torch.add(x, y, out=x)\n",
    "print('\\nAfter addition (x is modified):')\n",
    "print('x: ', x)\n",
    "print('y: ', y)\n",
    "print('z: ', z)\n",
    "print('z is x: ', z is x)\n",
    "print('z is y: ', z is y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uNTk5heeVTRr"
   },
   "source": [
    "일반적으로 **in-place 연산은 피하는 것이 좋습니다.**  \n",
    "이는 autograd를 사용해 gradient를 계산할 때 문제를 일으킬 수 있기 때문입니다  \n",
    "다만 in-place 연산을 하는 경우 memory를 아낄 수 있기 때문에 이를 잘 활용하는 것도 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uN6FfqU9wFeG"
   },
   "source": [
    "## Running on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ds6SDTbrwOc1"
   },
   "source": [
    "**주의: 이 섹션은 GPU가 필요합니다! CUDA 지원 GPU가 없는 경우, Google Colab에서 이 부분을 실행할 수 있습니다.**\n",
    "\n",
    "PyTorch의 가장 중요한 기능 중 하나는 GPU(Graphics Processing Unit)를 사용해 `tensor` 연산을 가속할 수 있다는 점입니다.  \n",
    "PyTorch가 GPU를 사용할 수 있도록 설정되어 있는지 쉽게 확인할 수 있습니다.  \n",
    "또한 `.to` 메서드를 사용하면 `tensor`를 원하는 장치로 옮길 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4792,
     "status": "aborted",
     "timestamp": 1599236804384,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "_RkoFEVVKWlW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch cannot use GPUs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print('PyTorch can use GPUs!')\n",
    "else:\n",
    "  print('PyTorch cannot use GPUs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4788,
     "status": "aborted",
     "timestamp": 1599236804385,
     "user": {
      "displayName": "Yunseok Jang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji2utsrQJWXntm3ishdCA23wmdDA4QyRS8UrqQsEQ=s64",
      "userId": "10051210866960976186"
     },
     "user_tz": 240
    },
    "id": "D03s614dMCvy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 device: cpu\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mx0 device:\u001b[39m\u001b[33m'\u001b[39m, x0.device)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Move it to the GPU using .to()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m x1 = \u001b[43mx0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mx1 device:\u001b[39m\u001b[33m'\u001b[39m, x1.device)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Move it to the GPU using .cuda()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\deutan\\github-all\\deep-learning\\2025-DNN-assignment1\\DNN-Assignment1\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Construct a tensor on the CPU\n",
    "x0 = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "print('x0 device:', x0.device)\n",
    "\n",
    "# Move it to the GPU using .to()\n",
    "x1 = x0.to('cuda')\n",
    "print('x1 device:', x1.device)\n",
    "\n",
    "# Move it to the GPU using .cuda()\n",
    "x2 = x0.cuda()\n",
    "print('x2 device:', x2.device)\n",
    "\n",
    "# Move it back to the CPU using .to()\n",
    "x3 = x1.to('cpu')\n",
    "print('x3 device:', x3.device)\n",
    "\n",
    "# Move it back to the CPU using .cpu()\n",
    "x4 = x2.cpu()\n",
    "print('x4 device:', x4.device)\n",
    "\n",
    "# We can construct tensors directly on the GPU as well\n",
    "y = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float64, device='cuda')\n",
    "print('y device / dtype:', y.device, y.dtype)\n",
    "\n",
    "# Calling x.to(y) where y is a tensor will return a copy of x with the same\n",
    "# device and dtype as y\n",
    "x5 = x0.to(y)\n",
    "print('x5 device / dtype:', x5.device, x5.dtype)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "kQndOAmiVTO3",
    "bCtoiSyVVTO8",
    "hQrEwOpXb9Gh",
    "zjosrOn8mOMV",
    "OgPaSNS2mVPn",
    "zeH5501nmh7W",
    "1MEmHrgBsgX4",
    "HrBSx6hYu8ca",
    "LWagwmXuvIle",
    "Yz_VDA3IvP33",
    "Rz_hiJD33fu1",
    "rlANfnILvX3S",
    "mo-PoTWNvbba",
    "4y93rPhGveWw",
    "oGt8ZPb_vixw",
    "Ad-xqELwyqpN",
    "Ql9_eXuU4OG8",
    "Z150qBob4Wkz",
    "f4SJCVbf-bZ0",
    "WJiiBxNE-X8g",
    "NgcdvD1evxTQ",
    "1BCVlPHZ4_Qz",
    "yDyH9USAuyZ-",
    "lRyLyXU2u29N",
    "mbCVOr2sVTRR",
    "UISn2pcf9QjY",
    "NlJs-yN4VTRp",
    "uN6FfqU9wFeG"
   ],
   "name": "pytorch101.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "DNN-Assignment1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
